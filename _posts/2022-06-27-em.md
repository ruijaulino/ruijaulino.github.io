# Expectation-Maximization and Applications






## A first example


Consider a distribution that is defined as a mixture of several distributions 
$p(x)=\sum_k \phi_k p_k(x)$. 
A graphical way to describe this distribution is 
$\phi \rightarrow z \rightarrow x$, 
as observations 
$x$ 
are generated by selecting a emission 
$z_k$ 
according to a probability 
$\phi_k$.

If we consider each emission to be a Gaussian then we have a Gaussian Mixture:

$p(x)=\sum_k \phi_k N(x;\mu_k,\Sigma_k)$

Let us simulate some observations from a univariate Gaussian Mixture. 


```python
import numpy as np
import matplotlib.pyplot as plt

def gauss_prob(x,mu,scale):
    return np.exp(-0.5*np.power((x-mu)/scale,2))/(scale*np.sqrt(2*np.pi))

def gmm_pdf(x,phi,mu,scale):
    pdf=np.zeros(x.size)
    for i in range(phi.size):
        pdf+=phi[i]*gauss_prob(x,mu[i],scale[i])
    return pdf

def simulate_gmm(n,phi,mu,scale):
    # simulate states
    z=np.random.choice(np.arange(phi.size,dtype=int),p=phi,size=n)
    # emit x from corresponding states
    x=np.random.normal(mu[z],scale[z])
    return x,z

# let us choose some parameters that exarcebate the histogram
phi=np.array([0.2,0.8])
mu=np.array([-1,1])
scale=np.array([0.5,0.5])
n=10000
x,z=simulate_gmm(n,phi,mu,scale)

x_pdf=np.linspace(-3,3,2000)
pdf=gmm_pdf(x_pdf,phi,mu,scale)

ax=plt.subplot(211)
plt.title('Some states')
plt.plot(z[:50])
plt.xticks([])
ax=plt.subplot(212)
plt.title('Corresponding observations')
plt.plot(x[:50])
plt.show()
plt.title('Density estimator of x from data / Theoretical value')
plt.hist(x,bins=50,density=True)
plt.plot(x_pdf,pdf,color='k',label='GMM pdf')
plt.legend()
plt.show()

```


![png](/images/em/output_2_0.png)



![png](/images/em/output_2_1.png)


A question that we can put now is, given a data set 
$X=\{x_0,x_1,\cdots,x_n\}$ 
and it seems that a Gaussian Mixture can be a good candidate distribution to model the observations, how to we determine it's parameters?

If we knew the state 
$z_i$ 
from where each observation 
$x_i$ 
was generated then, trivially, 
$\phi_k$ 
would be the number of times state 
$z_k$ 
is observed and the parameters 
$\mu_k$ 
and 
$\sigma_k^2$ 
can be (roughly) estimated with the mean and variance estimators of observations where state is 
$z_k$. 
Of course we do not observe 
$z$ 
in practice; we are assuming it exists because it may allow us to model model complex stuff.

As usual, a way to estimate the parameters 
$\theta$ 
is by finding the ones that maximize 
$p(\theta|X) \propto p(\theta)p(X|\theta)$; 
assuming a uniform prior, then we are interested in the set of parameters that maximize 
$p(X|\theta)$.

Since all observations are independent:

$L(\theta|X)=p(X|\theta)=\Pi_i ( \sum_k \phi_k N(x_i;\mu_k,\sigma_k^2) )$

where 
$L(\theta|X)$ 
is the likelihood function. Also, in logarithm (as is typical):

$l(\theta|X)=\log p(X|\theta)=\sum_i \log ( \sum_k \phi_k N(x_i;\mu_k,\sigma_k^2) )$

Let us try to solve the problem (find the maximum). For the location parameters:

$\frac{\partial l(\theta)}{\delta \mu_k}=0 \rightarrow \sum_i \frac{\phi_k N(x_i;\mu_k,\sigma_k^2)}{\sum_k \phi_k N(x_i;\mu_k,\sigma_k^2)} \frac{x_i-\mu_k}{\sigma_k^2} =0$

and we got stuck here (for example, in the case of finding the estimator of 
$\mu$ 
for a simple Gaussian distribution this reduces to simple mean estimator; here this does not apply).

Let us note the following:

$p(z_i=k|x_i)=\frac{p(x_i|z_i=k)p(z_i=k)}{p(x_i)}=\frac{\phi_k N(x_i;\mu_k,\sigma_k^2)}{\sum_k \phi_k N(x_i;\mu_k,\sigma_k^2)} = \gamma_i(k)$

from here we can see that a estimator for 
$\mu_k$ 
is a weighted average of 
$X$ 
(the weights are the probability that we are in that state). Replacing in the expression:

$\frac{\partial l(\theta)}{\delta \mu_k}=0 \rightarrow \sum_i \gamma_i(k) \frac{x_i-\mu_k}{\sigma_k^2}=0 \rightarrow \mu_k=\frac{\sum_i \gamma_i(k) x_i}{\sum_i \gamma_i(k)}$

We can also interpret 
$\sum_i \gamma_i(k)$ 
as 
$N_k$ 
as the number of times state 
$k$ 
is emitting. For the variance, the equivalent calculations yield:

$\sigma_k^2=\frac{1}{N_k} \sum_i \gamma_i(k)(x_i-\mu_k)^2$

Finally, an estimator for the probability of states is 
$\phi_k=N_k/N$.


So, with this, one can try to make an iterative procedure like:

1 - Initialize $\mu_k$,$\sigma_k^2$,$\phi_k$

2 - Evaluate $\gamma_i(k)$

3 - Estimate new values for $\mu_k$,$\sigma_k^2$,$\phi_k$

4 - Repeat 2 and 3 until values do not _change_.


Let's code this procedure for the previous example!


```python
# build some initial values 
phi=np.array([0.4,0.6],dtype=float)
mu=np.array([-0.1,0.1],dtype=float)
scale=np.array([0.1,0.1],dtype=float)

n_states=phi.size

print('Initial parameters')
print('PHI: ', phi)
print('MU: ', mu)
print('SCALE: ', scale)

n_iter=100
params_hist=np.zeros(n_iter)
# Iterate procedure
for n_it in range(n_iter):
    # estimate gamma
    params_hist[n_it]=mu[0]
    gamma=np.zeros((x.size,n_states))
    for j in range(n_states):
        gamma[:,j]=phi[j]*gauss_prob(x,mu[j],scale[j])
    gamma/=np.sum(gamma,axis=1)[:,None]
    n_k=np.sum(gamma,axis=0)
    # reestimate mu and scale
    for i in range(n_states):
        mu[i]=np.sum(gamma[:,i]*x)/n_k[i]
        scale[i]=np.sqrt(np.sum(gamma[:,i]*np.power(x-mu[i],2))/n_k[i])
    phi=n_k/x.size
print() 
print('Final parameters')
print('PHI: ', phi)
print('MU: ', mu)
print('SCALE: ', scale)

plt.title('Evolution of mu[0]')
plt.plot(params_hist)
plt.show()
```

    Initial parameters
    PHI:  [0.4 0.6]
    MU:  [-0.1  0.1]
    SCALE:  [0.1 0.1]
    
    Final parameters
    PHI:  [0.199061 0.800939]
    MU:  [-0.99936495  1.00419154]
    SCALE:  [0.50858217 0.50740375]



![png](/images/em/output_5_1.png)


It is possible to observe that the procedure converged and the parameters went to values quite similar to the true ones.


## Expectation-Maximization

The previous procedure to find the parameters of a model with hidden parameters seems to work. Now let us give an explanation on the why.

Consider a distribution parametrized by 
$\theta$ 
for 
$X$ 
(observed) and 
$Z$ 
(hidden), 
$p(X,Z|\theta)$. 
The objective is to maximize the likelihood (
$Z$ 
is discrete, otherwise it is an integral):

$p(X|\theta)=\sum_Z p(X,Z|\theta)$

Also, 
$p(X,Z|\theta)=p(Z|X,\theta)p(X|\theta)$ 
and, as a consequence, 
$\log p(X,Z|\theta)=\log p(Z|X,\theta) + \log p(X|\theta)$. 
Let us start by assuming that 
$Z$ 
has some distribution 
$q(Z)$; 
then:

$\log p(X,Z|\theta)=\log p(Z|X,\theta) + \log p(X|\theta) \rightarrow \sum_Z q(Z) \log p(X|\theta)=\sum_Z q(Z) ( \log p(X,Z,\theta) - \log p(Z|X,\theta) )$


We can observe that 
$\sum_Z q(Z) \log p(X|\theta)=\log p(X|\theta)$. 
Adding and subtracting 
$\log q(Z)$ 
inside the right hand side, allow us to write:

$\log p(X|\theta)= \sum_Z q(Z) \log \frac{p(X,Z|\theta)}{q(Z)} + (-1) \cdot \sum_Z q(Z) \log \frac{p(Z|X,\theta)}{q(Z)}$

The term 
$(-1) \cdot \sum_Z q(Z) \log \frac{p(Z|X,\theta)}{q(Z)}$ 
is the Kullbackâ€“Leibler divergence between 
$q(Z)$ 
and 
$p(Z|X,\theta)$ 
and, basically, represents the _cost_ of approximating 
$p(Z|X,\theta)$ 
with 
$q(Z)$; 
also this term is always positive. The other term, 
$\sum_Z q(Z) \log \frac{p(X,Z|\theta)}{q(Z)}$, 
we will call it 
$L(q,\theta)$; 
then:

$\log p(X|\theta)=L(q,\theta)+\text{KL}(q)$

note that, 
$L(q,\theta) \le \log p(X|\theta)$ 
(as the second term is always positive) and so it is a lower bound for 
$\log p(X|\theta)$.


If we find a maximum for the lower bound then we necessarily increase the likelihood. With respect to 
$q$, 
we can notice that 
$L(q,\theta)= \log p(X|\theta)-\text{KL}(q)$ 
and so, 
$L(q,\theta)$ 
will be maximum when 
$\text{KL}(q)$ 
is zero because 
$\log p(X|\theta)$ 
does not depend on 
$q(Z)$; 
to do this, we can set 
$q(Z)=p(Z|X,\theta_0)$. 
Now, with 
$q(Z)$ 
fixed, we can find the parameters 
$\theta_1$ 
that maximize 
$L(q,\theta)$. 
In the end, under these new parameters, 
$\log p(X|\theta_0) \le \log p(X|\theta_1)$.

#### E-STEP

Starting from 
$\theta_0$, 
to make KL zero, we can observe that this is verified when 
$q(Z)=p(Z|X,\theta_0)$. 
So we just need to evaluate this quantity with the current parameters.

#### M-STEP

Now we need to maximize 
$L(q,\theta)$ 
with 
$q(Z)$ 
held fixed from the previous iteration. Writting

$L(q,\theta)=\sum_Z p(Z|X,\theta_0) \log p(X,Z|\theta) - \sum_Z p(Z|X,\theta_0) \log p(Z|X,\theta_0) = Q(\theta,\theta_0)+\text{const}$

we see that we need to maximize 
$\sum_Z p(Z|X,\theta_0) \log p(X,Z|\theta)$.


 

### GMM Revisited

The previous example with a Gaussian Mixture can be revised under this general formulation. Starting from some parameters 
$\theta_0$ 
we can write:

##### E-STEP

To set KL to zero we need to consider 
$q(Z)=p(Z|X,\theta_0)$, 
which, for every observation reduces to:

$p(z_i=k|x_i,\theta_0)=\frac{p(x_i|z_i=k,\theta_0)p(z_i=k|\theta_0)}{p(x_i|\theta_0)}=\gamma_i(k)$

this is same result as we had before.

##### M_STEP

To maximize 
$p(X,Z|\theta_0)$ 
with 
$q(Z)$ 
fixed, we can notice that, as discussed before, the estimators were 

$\mu_k=\frac{\sum_i \gamma_i(k) x_i}{\sum_i \gamma_i(k)}$, 
$\sigma_k^2=\frac{1}{N_k} \sum_i \gamma_i(k)(x_i-\mu_k)^2$ 
and 
$\phi_k=N_k/N$ . 

Since the 
$\gamma_k(i)$ 
are supposed to be held constant then it follows that the reestimation formulas for the parameters are the same as before.


#### Multivariate case and Conditional Distribution

The previous expressions are easily extended for a multivariate Gaussian in each state (i.e, we are modelling 
$x \in \mathbb{R}^p$). 
The _E-STEP_ remains the same (but with probability of observations from a multivariate Gaussian distribution) and the _M-STEP_ should be:

$\vec \mu_k = \frac{1}{N_k} \sum_i \gamma_i(k) \vec x_i $


$\vec \Sigma_k = \frac{1}{N_k} \sum_i \gamma_i(k) (\vec{x_i}-\vec \mu_k ) (\vec{x_i}-\vec \mu_k )^T $

$\phi_k=\frac{N_k}{N}$

An interesting computation is when 
$x \in \mathbb{R}^p$ 
is modelled as a GMM and now we want some conditional distribution; for example, let 
$\vec x=\{\vec x_1,\vec x_2\}$ 
(we are dividing the variables in two sets) and we know the current value of variables 
$\vec x_2=\vec q_2$ 
(and the model, of course). How to compute the conditional 
$p(\vec x_1 | \vec x_2=\vec q_2)$?.


Recall that, if 
$\vec x=\{\vec x_1,\vec x_2\}$ 
and 
$p(\vec x)=N(\vec \mu,\Sigma)$, 
then 

$\vec \mu_{x_1|x_2}=\vec \mu_{x_1} + \Sigma_{x_1,x_2} \Sigma_{x_2,x_2}^{-1} (\vec x_2 - \vec \mu_{x_2}) $

and

$\Sigma_{x_1|x_2}=\Sigma_{x_1,x_1}-\Sigma_{x_1,x_2}\Sigma_{x_2,x_2}^{-1}\Sigma_{x_2,x_1}$
 
where the subscripts indicate submatrices.

To compute the result, by definition, 
$p(x_1|x_2)=\frac{p(x_1,x_2)}{p(x_2)}=\frac{\sum_k \phi_k N(\mu_k,\Sigma_k)}{p(x_2)}$. 
Also, (seems a bit redundant but will help), 
$p(x_1|x_2)=\frac{p(x_1|x_2)p(x_2)}{p(x_2)}$. 
The marginal for 
$\vec x_2$ 
is just 
$p(\vec x_2)=\sum_k \phi_k N(\vec x_2; \mu_{k,\vec x_2},\Sigma_{k,\vec x_2 \vec x_2})$.


Replacing:

$p(\vec x_1 | \vec x_2=\vec q_2) = \frac{\sum_k \phi_k N(\vec q_2; \mu_{k,\vec x_2},\Sigma_{k,\vec x_2 \vec x_2}) N(\vec x_1;\mu_{k;\vec x_1|\vec x_2},\Sigma_{k,\vec x_1|\vec x_2})}{\sum_l \phi_l N(\vec q_2; \mu_{l,\vec x_2},\Sigma_{l,\vec x_w \vec x_2})}$


Which can be seen as a Gaussian Mixture as well, but the mixing coefficients are given by how _close_ the query point 
$\vec q_2$ 
are to each distribution.


#### A note in initialization

The previous simple univariate case converged easily but sometimes this can be an issue when the initial parameters are too far from the optimal ones. One solution is to generate random parameters, iterate many times and check which set of parameters have the largest probability (this should be easy to compute given the found parameters and the formulas above). Even doing this, convergence may be difficult; an approach that seems to work well is to perform clustering first (you dont need to run all the iterations) and use the clusters statistics as initial values for the procedure (
$\phi$ 
will be proportional to the number of points in each cluster). Then, a final refine can be made with the best random run as starting parameters.



## Sequential Data


For many problems, it can make sense to model the observations as having dependencies between then. If this is the case, probability of observations 
$X=\{x_1,\cdots,x_n\}$ 
cannot be factored as a product of probabilities.

In graphical terms, we could add dependencies among observations like:

$x_1 \rightarrow x_2 \rightarrow \cdots x_n$

where, in this case, the current observation dependends on the previous one. Of course one could add complexity to the model by adding dependence on a more distant past, 
$p(x_n|x_1,\cdots,x_{n-1})=p(x_n|x_{n-m},\cdots,x_{n-1})$. 
For there situations, one can build a time delay embedding and consider the observations as independent (maybe removing some points in the middle to make sure that the independence assumption makes sense) and then the regular methods can apply. Adding dependencies will increase the complexity of the model and may turn it's estimation unviable.

A way to add complexity/dependencies without growing the model too much is to consider the existence of a _latent_ (hidden) variable 
$Z=\{z_1,z_2,\cdots,z_n\}$ 
which encodes information about the sequence until the current observation. Given the current value of 
$z_i$ 
then the distribution on $x_i$ is determined. This is similar to a mixture model, but the next emission state depends on previous states. Graphically:

$z_1 \rightarrow z_2 \rightarrow $

$ \downarrow \\ \\ \\ \\ \\ \downarrow$

$x_1 \\ \\ \\ \\ x_2$


Given this structure, we can write the joint distribution as:

$p(x_1,\cdots,x_n,z_1,\cdots,z_n)=p(z_1) \Pi_i p(z_i|z_{i-1}) \Pi_i(x_i|z_i)$


### HMM

If the latent variables are discrete we get what is called an Hidden Markov Model. If we look a time instant of the process, the distribution of 
$x$ 
is a mixture distribution where the components are the probabilities that the emitting state is 
$k$.


Since the states are discrete, we can model 
$p(z_i|z_{i-1})$ 
with a matrix 
$A$ 
where 
$A_{k_1,k_2}=p(z_i=k_1|z_{i-1}=k_2)$. 
Also, we need to define the initial state probabilities 
$P_k=p(z_1=k)$.


Now, for each state there will be a emitting distribution 
$p(x_i|z_i=k,\phi)$, 
which can depend on some parameters 
$\phi$.


Under this formulation, we can write the joint distribution of the model given the parameters:


$p(X,Z|\theta)=p(z_1|P) \cdot \Pi_i p(z_i|z_{i-1},A) \cdot \Pi_j p(x_j|z_j,\phi) $

with 
$\theta=\{P,A,\phi\}$.

Let gain some intuition by simulating a univariate HMM process.



```python
def simulate_hmm(n,A,P,mu,scale):
    states=np.arange(A.shape[0],dtype=int)
    z=np.zeros(n,dtype=int)
    x=np.zeros(n)
    z[0]=np.random.choice(states,p=P)
    x[0]=np.random.normal(mu[z[0]],scale[z[0]])
    for i in range(1,n):
        z[i]=np.random.choice(states,p=A[z[i-1]])
        x[i]=np.random.normal(mu[z[i]],scale[z[i]])
    return x,z
# PARAMETERS
A=np.array([[0.9,0.1],[0.1,0.9]])
P=np.array([0.5,0.5])
mu=np.array([-1,1])
scale=np.array([0.5,0.5])
n=2000

x,z=simulate_hmm(n,A,P,mu,scale)
ax=plt.subplot(211)
plt.title('States Sequence')
plt.plot(z[:100],color='r')
plt.xticks([])
ax=plt.subplot(212)
plt.title('Observations Sequence')
plt.plot(x[:100])
plt.show()
    
```


![png](/images/em/output_11_0.png)


As was defined in the matrix 
$A$, 
the states are somewhat sticky (red line; if we are in a state, we tend to stay there). It is noticeable the different mean when we are in state 0 or in state 1 (blue plot).



Now, given that we have a sequence of observations 
$X$, 
how to find the parameters that fit better an HMM? As was the case with the GMM, we have hidden variables, and so, it is possible to try to use Expactation-Maximization to iterate to a solution.


This should reduce to perform the _E-STEP_ and _M-STEP_ of EM. Let us see how.


The log joint probability is:

$\log p(X,Z|\theta) = \log p(z_1|\theta) + \sum_i \log p(z_i|z_{i-1},\theta) + \sum_j p(x_j|z_j,\theta)  $

The 
$Q$ 
function to be maximized, 
$Q(\theta,\theta_0)$, 
is:

$Q(\theta,\theta_0)$=$\sum_Z p(Z|X,\theta_0) \log p(X,Z|\theta) = \sum_Z \left( p(Z|X,\theta_0) \log p(z_1|\theta) \right) + \sum_Z \left( p(Z|X,\theta_0) \sum_i \log p(z_i|z_{i-1},\theta) \right) +  \sum_Z \left( p(Z|X,\theta_0) \sum_j p(x_j|z_j,\theta) \right)$


To help with the formulation, let us define (in a similar way as with the Gaussian mixture), the following variables (assuming for now that we can compute them):

$\gamma_i(k)=p(z_i=k|X,\theta)$

$\xi_{i,i-1}(k_1,k_2)=p(z_i=k_1,z_{i-1}=k_2|X,\theta)$

Let us assume now that, for some set of parameters 
$\theta_0$ 
we can compute these quantities. It is easier to consider each term in 
$Q$ 
individually:

##### First term

$T_1=\sum_Z \left( p(Z|X,\theta_0) \log p(z_1|\theta) \right) = \sum_k \gamma_1(k) \log P_k$

Maximization of 
$T_1$ 
subjected to 
$\sum_{k'}P_{k'}=1$ 
gives (derivate and equate to zero; use Lagrange multipliers to add the constraint) that an estimator for 
$P_k$ 
is:

$P_k=\frac{\gamma_1(k)}{\sum_{k'} \gamma_1(k')}$



##### Second term

$T_2=\sum_Z \left( p(Z|X,\theta_0) \sum_i \log p(z_i|z_{i-1},\theta) \right) = \sum_{k_1} \sum_{k_2} \sum_i \xi_{i,i-1}(k_1,k_2) \log A_{k_1,k_2}$

There are constraints on 
$A$ 
as 
$\sum_j A_{i,j}=1$. 
Solving the maximization problem, one can estimate 
$A$ 
as

$A_{k_1,k_2}=\frac{\sum_i \xi_{i,i-1}(k_1,k_2)}{\sum_{k_1} \sum_i \xi_{i,i-1}(k_1,k_2)}$


##### Third term

We can notice that the last term has the same form as a mixture of distributions:

$T_3=\sum_Z \left( p(Z|X,\theta_0) \sum_j p(x_j|z_j,\theta) \right) = \sum_k \sum_i \gamma_i(k) \log p_k(x_i|\theta) $

For example, in the Gaussian mixture case we have seen that:

$\vec \mu_k = \frac{1}{\sum_i \gamma_i(k)} \sum_i \gamma_i(k) \vec x_i $

$\vec \Sigma_k = \frac{1}{\sum_i \gamma_i(k)} \sum_i \gamma_i(k) (\vec{x_i}-\vec \mu_k ) (\vec{x_i}-\vec \mu_k )^T $


### Forward-Backward algorithm

There is a efficient procedure to estimate 
$\gamma_i(k)$ and $\xi_{i,i-1}(k_1,k_2)$ - which 
is the _E-STEP_ of expectation maximization. Let us derive it.

Using Bayes rule:

$\gamma_i(k) = p(z_i=k|X) = \frac{p(X|z_i=k)p(z_i=k)}{p(X)}$


due to the sequential nature of data (observations are independent given the state):

$\gamma_i(k) = \frac{p(x_1,\cdots,x_n,z_n=k)p(x_{n+1},\cdots x_N|z_n=k)}{p(X)} = \frac{\alpha(k)\beta(k)}{p(X)}$

with:

$\alpha_i(k)=p(x_1,\cdots,x_n,z_i=k)$

$\beta_i(k)=p(x_{n+1},\cdots, x_N|z_i=k)$

These definitions can be worked out to yield the following recursive relations:

##### Forward
$\alpha_i(k)=p(x_i|z_i=k) \sum_{k'} \alpha_{i-1}(k')p(z_i=k|z_{i-1}=k')$

##### Backward
$\beta_i(k)= \sum_{k'} \beta_{i+1}(k') p(x_{i+1}|z_{i+1}=k')p(z_{i+1}=k'|z_i=k) $

##### Joint term

Finally, the joint term can evaluated as

$\xi_{i,i-1}(k_1,k_2) = p(z_{i}=k_1,z_{i-1}=k_2|X)=\frac{p(X|z_{i}=k_1,z_{i-1}=k_2)p(z_{i}=k_1,z_{i-1}=k_2)}{p(X)}$ 

Manipulating we have


$\xi_{i,i-1}(k_1,k_2) = \frac{\alpha_{i-1}(k_2) p(x_i|z_i=k_1) p(z_i=k_1|z_{i-1}=k_2) \beta_i(k_1)}{p(X)}$


These formulas allow one to compute 
$\gamma$ 
and 
$\xi$ 
given a set of model parameters 
$\theta$; 
then it is possivel to perform the maximization step as described above. As before, this is an iterative procedure that must be repeated until convergence.


#### Scaling

In practice, the forward and backward recursions will suffer for under/overflow of computations since they can potentially be the product of many terms. One way to stabilize the calculations is to normalize somehow the quantities. Consider the following formulation:

$\hat \alpha_i(k) = p(z_i=k|x_1,\cdots,x_i) = \frac{\alpha_i(k)}{p(x_1,\cdots,x_i)}$

This 
$\hat \alpha$ 
is within machine precision as it is just the probability of a given state given the previous data. Given the model, all 
$x_i$ 
are independent; so 
$p(x_1,\cdots,x_i)=\Pi_{m=1}^i c_m$ 
and 
$\alpha_i(k) = \hat \alpha_i(k) \cdot \Pi_{m=1}^i c_m$. 
Since all 
$c_m$ 
are independent, replacing in the previous (forward) relation:

$c_i \hat \alpha_i(k)=p(x_i|z_i=k) \sum_{k'} \hat \alpha_{i-1}(k')p(z_i=k|z_{i-1}=k')$


For the backward procedure, 
$\beta_i(k)=p(x_{n+1},\cdots, x_N|z_i=k)$, 
and so, a natural normalization is to divide this value by 
$p(x_{n+1},\cdots, x_N)$. 
If we do this:


$\beta_i(k) = \hat \beta_i(k) \cdot \Pi_{m=i+1}^N c_m$

And the backward recursion becomes:

$c_{i+1} \hat \beta_i(k)= \sum_{k'} \hat \beta_{i+1}(k') p(x_{i+1}|z_{i+1}=k')p(z_{i+1}=k'|z_i=k) $

These scaling factors also simplifies other computations as:

$p(X)=\Pi_i c_i \rightarrow \log p(X) = \sum_i \log c_i$

and

$\gamma_i(k) = \hat \alpha_i(k) \hat \beta_i(k)$

$\xi_{i,i-1}(k_1,k_2) = c_i \hat \alpha_{i-1}(k_2) p(x_i|z_i=k_1) p(z_i=k_1|z_{i-1}=k_2) \hat \beta_i(k_1)$



### Predictive Distribution

As is natural, one is interested in the predictive distribution of the model. Suppose we observed 
$X=\{x_1,\cdots,x_n\}$ 
and now we want to make a prediction for 
$x_{n+1}$. 
This is equivalent to compute 
$p(x_{n+1}|X)$.

$p(x_{n+1}|X)=\sum_{k'} p(x_{n+1},z_{n+1}=k'|X)=\sum_{k'} p(x_{n+1}|z_{n+1}=k')p(z_{n+1}=k'|X) = \frac{1}{p(X)} \sum_{k'} p(x_{n+1}|z_{n+1}=k') \sum_k p(z_{n+1}=k'|z_n=k) \alpha_n(k)$


We can see that this is equivalent to run the forward procedure until the end of the sequence and then propagating with 
$A$ 
to get the next state distribution. Then the prediction is just a mixture distribution where the weights are given by 
$A \cdot \alpha_n$.


### Numerical example 

Let us build a simple implementation of the procedure to learn the parameters of the observations sequence generated previously.



```python
def forward(prob,A,P):
    '''
    Forward Procedure 
    Calculates the probability of the sequence given the model
    alpha[i] = Pr(O1 O2 ... Ot,state @ t = state i | model)
    prob: numpy (n_obs,n_states) array with the probability
        of the observations given each state (each column is this probability)
    A: numpy (n_states,n_states) array with the state transition probability distribution
    P: numpy (n_states,) array with the initial state distribution

    output
        alpha: numpy (n_obs,n_states) array with the
            renormalized alphas at each period 
        c: numpy (n_obs,) array with the renormalization
            factor at each time stamp
    '''
    n_states=A.shape[0]
    n_obs=prob.shape[0]
    alpha=np.zeros((n_obs,n_states),dtype=np.float)
    c=np.zeros(n_obs,dtype=np.float)
    alpha[0]=P*prob[0]
    c[0]=1/np.sum(alpha[0])
    alpha[0]*=c[0]
    for i in range(1,n_obs):
        alpha[i]=np.sum(A*alpha[i-1][:,None],axis=0)*prob[i] 
        c[i]=1/np.sum(alpha[i])
        alpha[i]*=c[i]
    return alpha,c

def backward(prob,A,c):
    '''
    Backward Procedure 
    Calculates the probability 

    beta[i] = Pr(Ot+1 Ot+2 ... OT | state @ t = state i , model)

    prob: numpy (n_obs,n_states) array with the probability
        of the observations given each state (each column is this probability)
    A: numpy (n_states,n_states) array with the state transition probability distribution
    c: numpy (n_obs,) array with the renormalization factor at each time stamp
        ** from forward() **
    output
        beta: numpy (n_obs,n_states) array with the
            betas at each period
    '''
    n_states=A.shape[0]
    n_obs=prob.shape[0]
    beta=np.zeros((n_obs,n_states),dtype=np.float)
    beta[-1]=np.ones(n_states,dtype=np.float)
    beta[-1]*=c[-1]
    for i in range(n_obs-2,-1,-1):
        beta[i]=np.sum(A*(prob[i+1]*beta[i+1]),axis=1)
        beta[i]*=c[i]
    return beta

def baum_welch_step(prob,A,P):
    '''
    Iteration step of the Baum-Welch algorithm
    returns: ml,A,P,gamma
    '''
    n_states=A.shape[0]
    n_obs=prob.shape[0]
    alpha,c=forward(prob,A,P)
    beta=backward(prob,A,c)
    gamma=alpha*beta
    gamma/=c[:,None]
    ml=np.sum(gamma[0])
    gamma/=ml
    A_tensor=np.array([A])
    A_tensor=np.tile(A_tensor,(n_obs-1,1,1))
    xi=(prob[1:]*beta[1:])[:,None]*A_tensor*alpha[:-1][:,:,None]
    xi/=ml
    p=gamma[0]
    A=np.sum(xi,axis=0)/np.sum(gamma[:-1],axis=0)[:,None]
    ml=-1*np.sum(np.log(c))
    return ml,A,P,gamma

class GaussianEmmission(object):
    '''
    Simple class with a Gaussian emission for an HMM
    '''
    def __init__(self,mu,scale):
        self.mu=mu
        self.scale=scale
    
    def view(self):
        print('Gaussian Emission N(%s,%s)'%(self.mu,self.scale))
    
    def probability(self,x):
        '''
        Compute probability of each observation
        in x given the parameters
        '''
        return np.exp(-0.5*np.power((x-self.mu)/self.scale,2))/(self.scale*np.sqrt(2*np.pi))
    
    def reestimate(self,x,gamma):
        '''
        Re-estimate parameters under gamma
        '''
        d=np.sum(gamma)
        mu=np.dot(x,gamma)
        mu/=d
        var=np.dot(np.power(x-mu,2),gamma)/d
        scale=np.sqrt(var)
        self.mu=mu
        self.scale=scale
        
```


```python
# make initial guess for parameters
P_est=np.array([0.5,0.5])
A_est=np.array([[0.6,0.4],[0.4,0.6]])
emissions=[]
# initialize first emission
emissions.append(GaussianEmmission(mu=-0.1,scale=0.1))
emissions.append(GaussianEmmission(mu=0.1,scale=0.1))


print('Initial parameters')
print('P')
print(P_est)
print('A')
print(A_est)
print('EMISSIONS')
for e in emissions:
    e.view()

# ITERATE EM ALGORITHM
n_iter=50
n_states=2

# store model likelihood here
ml_history=[]
A_entry_history=[]
for i in range(n_iter):
    A_entry_history.append(A_est[0,0])
    # evaluate prob
    prob=np.zeros((x.size,n_states))
    for j in range(n_states):
        prob[:,j]=emissions[j].probability(x)
    
    ml,A_est,P_est,gamma=baum_welch_step(prob,A_est,P_est)
    # reestimate distributions parameters with gamma
    for j in range(n_states):
        emissions[j].reestimate(x,gamma[:,j])
    
    ml_history.append(ml)

print()
print()
print('Final parameters')
print('P')
print(P_est)
print('A')
print(A_est)
print('EMISSIONS')
for e in emissions:
    e.view()
    
# plot convergence of A[0,0]
plt.title('A[1->1] convergence')
plt.plot(A_entry_history,'.-')
plt.grid(True)
plt.show()
    
# plot convergence of model probability
plt.title('log P(X|M) convergence')
plt.plot(ml_history,'.-')
plt.grid(True)
plt.show()

```

    Initial parameters
    P
    [0.5 0.5]
    A
    [[0.6 0.4]
     [0.4 0.6]]
    EMISSIONS
    Gaussian Emission N(-0.1,0.1)
    Gaussian Emission N(0.1,0.1)
    
    
    Final parameters
    P
    [0.5 0.5]
    A
    [[0.8918656 0.1081344]
     [0.0874553 0.9125447]]
    EMISSIONS
    Gaussian Emission N(-1.0148879751716946,0.5206806989112945)
    Gaussian Emission N(0.9897135620277928,0.48870536753781985)



![png](/images/em/output_18_1.png)



![png](/images/em/output_18_2.png)


### Implementation notes

From a programming point of view, it makes sense to implement _distributions_ classes and use them to compute the probability vector. Each class must contain a re-estimation method that can estimate the it's parameters under a set of _weights_ 
$\gamma$. 
If we can do this for a distribution then the code is quite general; extensions to multivariate observations are _trivial_.


There is also the issue of initialization. A strategy that may work is to make many random parameters runs and then select the one with highest $p(X|M)$ - then some, extra iterations can be done to refine the solution. 

