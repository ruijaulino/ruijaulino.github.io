
# Optimal Strategies and Model Probability

In generic and intuitive terms, if a model is _better_ it should make more money. Let us try to give an explanation on how can we compare errors and probabilities looking at the result of making bets based on the predicitons of a model. 

Consider a sequence of returns $y_1, y_2, \cdots$ that can be predicted with some features $x_1, x_2, \cdots$. It makes sense to consider a model of the form $y\|x \sim N(\mu(x), C(x))$ - the conditional distribution of $y$ is approximated with a normal where location and scale depend on the features 
(think for example a linear regression); this type of approach is used in many regression problems and, even if the model is more complex (let's say it predicts a mixture) we can always approximate the predictive distribution as an equivalent normal by moment matching.

Of course the true data distribution is unknown and all of this are approximations. Let's use the notation $y\|x \sim N(m(x), Q(x))$ to designate the closest normal distribution (in moments) to the true one and use that as a reference model (after all the objective here is to create intuition). 
All this construction means that we care about the first and second moments.

Independently of the model structure (linear, non linear, constant or varying variance, mixtures, etc) it will have some associated parameters $\theta$ that need to be estimated. We can consider that a (train) dataset exists and from it we produce an estimate $\hat{\theta}$ that make the model
_adjust_ well to the observations (MAP or MLE).

As discussed in other notes, the capital grows as

$S_n = S_0 \exp \left( n \frac{1}{n} \log \left(1 + w(x)^T y \right) \right) = S_0 \exp \left( n G \right)$

from where we can write

$G \rightarrow \mathbb{E}\left\[ \log \left( 1+w(x)^T y \right)\right\] \approx \mathbb{E}\left\[ w(x)^T y - \frac{1}{2} w(x)^T y y^T w(x)\right\]$

Of course the expectations are to taken with respect to the true distribution; the weighting scheme that optimize $G$ is $w(x)^* \approx Q(x)^{-1} m(x)$ (using the above notation on the _true_ distribution and the approximation that the second non central moment is close the covariance). Since we do 
not have access to the true distribution, we can use our estimated model (with parameters $\hat{\theta}$) and, consequentially, $w(x) = C(x)^{-1} \mu(x)$.

On a new (test) dataset (or in production), we get a different growth rate

$G = \mathbb{E}\left\[ \mu(x)^T C(x)^{-1} y - \frac{1}{2} \mu(x)^T C(x)^{-1} y y^T C(x)^{-1} \mu(x) \right\]  = \mathbb{E}_x \left\[ \mu(x)^T C(x)^{-1} m(x) - \frac{1}{2} \mu(x)^T C(x)^{-1} Q(x) C(x)^{-1} \mu(x) \right\]$

Also, in this dataset, the (log) data evidence is

$\log p(D\|m) = -\frac{n}{2}\left( d\log(2\pi) + \mathbb{E}\left\[\|C(x)\|\right\] + \mathbb{E}\left\[ (y-\mu(x))^T C(x)^{-1} (y-\mu(x)) \right\]  \right)$

which we can write as

$\log p(D\|m) = -\frac{n}{2}\left( d\log(2\pi) + \mathbb{E}\left\[\|C(x)\|\right\] + \mathbb{E}\left\[ \text{tr}(C(x)^{-1} Q(x))  \right\] -2\mathbb{E}\left\[ \mu(x)^T C(x)^{-1} m(x) - \frac{1}{2} \mu(x)^T C(x)^{-1} \mu(x)  \right\]  \right)$

It is known that covariance is relatively easy to be predicted (tends to cluster, is easy to predict but difficult to trade) and it makes sense to make another approximation: the estimated model will predict a covariance _close_ to the true one: $C(x)^{-1}Q(x) \approx I$. This also mean 
that all covariances will be similar (for sure a model that predicts a time varying covariance has a different prediction than a model with a constant one but one can expect they will be similar on average). With this approximation

$G \approx \mathbb{E}_x \left\[ \mu(x)^T C(x)^{-1} m(x) - \frac{1}{2} \mu(x)^T C(x)^{-1} \mu(x) \right\] $

and

$\log p(D\|m) \approx -\frac{n}{2}\left( d\log(2\pi) + \mathbb{E}\left\[\|C(x)\|\right] + d -2\mathbb{E}\left\[ \mu(x)^T C(x)^{-1} m(x) - \frac{1}{2} \mu(x)^T C(x)^{-1} \mu(x)  \right\]  \right) =  -\frac{n}{2}\left( d\log(2\pi) + \mathbb{E}\left\[\|C(x)\|\right\] + d -2G  \right)$

putting together all approximations

$\log p(D\|m) \approx \text{const} + n G$

From where we can conclude that a higher $G$ means a higher $p(D\|m)$ if we use optimal betting $w(x) = C(x)^{-1} \mu(x)$.

This result connects the classic model selection with the performance of a optimal strategy. If we have two competing models it is common to compare them in terms of $p(m_i\|D)>p(m_j\|D)$. Assuming they have equal prior probabilities, this yields the condition 

$\log p(D\|m_i) > \log p(D\|m_j)$

with these results it is possible to compare them by the performance of a optimal trading strategy.

