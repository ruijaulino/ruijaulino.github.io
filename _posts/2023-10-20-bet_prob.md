# Betting and Data Probability





Consider the problem where we have a variable $y$ that we are trying to model with a variable $x$, i.e, $y=f(x)$ ($y \in \mathbb{R}^p$,$x \in \mathbb{R}^q$); this is known as a regression problem. At our disposal is joint observations of $x$ and $y$, $D=[(x_1,y_1),(x_2,y_2),\cdots,(x_n,y_n)]$. Of course there is uncertainty on the determination of this function/model $f(\cdot)$ and a probabilistic description makes sense. Let us assume that, for some value of $y$, we can write:


$p(y\|x) = N(\mu(x),C(x))$

This means that we are only interested in the distribution of $y\|x$ up to the second moment and we will use the Gaussian form for this; for example, if $y$ is unidimensional, $C(x)=\sigma^2$ is a constant and $\mu(x)=a+bx$ is linear then this is a linear regression.





If all observations in $D$ are independent we can calculate the probability of the data as $p(D) = \Pi_i p(y_i\|x_i)$; more usefull is it's logarithm (note that $C_i = C(x_i)$ and $\mu_i=\mu(x_i)$):

$\log p(D) = \sum_i p(y_i\|x_i) = -\frac{1}{2} \sum_i p\log(2\pi) + \log(\|C_i\|) + (y_i-\mu_i)^T C_i^{-1} (y_i-\mu_i) $

For the previous case of the univariate linear regression: 

$\log p(D) = -\frac{1}{2} \left( n \log(2\pi) + n \log(\sigma^2) + \frac{1}{\sigma^2} \sum_i (y_i-\mu_i)^2 \right)$

where the last term, $\sum_i (y_i-\mu_i)^2 = \sum_i (y_i-a-bx_i)^2$ can be identified with the squared error. Because of the negative sign, the maximum of probability if attained when this error is minimum. The concept of (mean) squared error is used many times as the target/objective for a regression problem (not just the linear regression case described); of course the interest is in error out-of-sample and, in the absence of abundant data, some resampling is needed to estimate this (like cross-validation).



Another interesting case is when the functions, $C_i = C(x_i)$ and $\mu_i=\mu(x_i)$, can take a finite set of values, i.e, depending on $x_i$ we have $C_k$ and $\mu_k$ (with a finite $k$). If this is the case we can group observations into sets where it's $x_j$ yield the same model with $C_k$ and $\mu_k$ (and sum over all $k$).

$\log p(D) = -\frac{n}{2} \left[ p\log(2\pi) + \sum_k \frac{n_k}{n}\log(\|C_k\|) + \sum_k \frac{n_k}{n} \frac{1}{n_k} \sum_j (y_j-\mu_k)^T C_k^{-1} (y_j-\mu_k) \right]$

For example, we can interpret the linear regression at this light: imagine we discretize the values of $x$; for each bucket we created we have a expected value of $a+bx_k$ (also, the variance is constant). Taking the limit of many buckets this is the same thing (also, $\frac{n_k}{n}$ is a measure of the distribution of $x$). 




A model should be interpreted as a solution to a problem: a simplification of the reality that has practical implications on decision making: it is natural to evaluate them according to the benefict they provide. If we are building a model with the objective to make bets with it, it makes more sense to evaluate how much money we make usign it than to compute some error metric. 

In the end, usign a model is a decision problem: a set of actions $a$ that can be taken and states of the world $w$; for each action and observed state we are rewarded with a utility $u(a,w)$. Of couse, the optimal action is the one that maximizes the reward given the observed state of the world; because we cannot known in advance what the future is, we have to choose the action under some expectation of what $w$ is - optimize the expected value.  

For example, we can interpret the regression, $y=f(x)$, as a decision problem: we have a unknown value of $y$ (the state of the world) and our action $a$ is the prediction; the utility is the reward of using $a$ as a estimation for $y$ (for example, the utility can be the squared error). 


For a financial application (develop a trading strategy using some probabilistic model between $y$ and $x$) it makes sense to consider the sequential investment problem; recalling the dynamics of the capital ($y_i$ is a vector of returns): 

$S_n=S_0 \cdot (1+ y_1^Tw_1) \cdot (1+ y_2^Tw_2) \cdots$

Notice that weights change over time. The growth rate can be expressed as

$G=\frac{1}{n} \sum_i \log(1+ y_i^Tw_i)$

Given our model (that $y$ depends on $x$), the distribution of returns can change because of the presence (conditioning) of this extra variable; without loss of generality let us say that this $x$ can take a finite set of values. With that in mind, let us group the previous terms by the distribution (i.e, because of the value of $x$) where they come from:

$G=\sum_k \frac{n_k}{n} \left( \frac{1}{n_k} \sum_{i_k} \log(1+ y_{i_k}^Tw_k) \right)$

which by the law of large numbers (and then using the Taylor expansion) is

$G=\sum_k p_k \mathbf{E}[\log(1+ y^Tw_k)]\\|_{k} \approx \sum_k p_k ( w_k^T\mu_k - \frac{1}{2}  w_k^T C_k w_k)$ 

where $p_k$ represents the probability that the returns comes from distribution $k$ - 
or in more detail, how many times over time we see returns coming from distribution $k$.

The optimal allocation (our action) depends on the next distribution of returns. If this distribution is $k$ then $w_k^* = C_k^{-1} \cdot \mu_k$ (this is easy to verify as all distributions are independent and so taking the derivative in order to each $w_k$ yields this result).


This optimal action yields a utility:

$u_t = y_t^T C_{y\|x_t}^{-1}\mu_{y\|x_t}$


If we have many successive observations of $u_t$ this has the clear interpretation that this is the returns of the investment strategy; also, we can take the mean $\bar{u} = \mathbb{E}(u_t)$ or other statistics of it.


Well, why is this interesting? Let us recall the expression for $\log p(D)$:

$\log p(D) = -\frac{n}{2} \left[ p\log(2\pi) + \sum_k \frac{n_k}{n}\log(\|C_k\|) + \sum_k \frac{n_k}{n} \frac{1}{n_k} \sum_j (y_j-\mu_k)^T C_k^{-1} (y_j-\mu_k) \right]$

and focus on the term $T=\frac{1}{n_k} \sum_j (y_j-\mu_k)^T C_k^{-1} (y_j-\mu_k)$. Expanding

$T=\frac{1}{n_k} \sum_j \left[ y_j^T C_k^{-1} y_j -2 y_j^T C_k^{-1} \mu_k + \mu_k^T C_k^{-1} \mu_k \right] = 
\frac{1}{n_k} \sum_j \text{Tr} \left( C_k^{-1} \sum_j y_j y_j^T \right) + \text{Tr} \left( C_k^{-1} \mu_k \mu_k^T \right) - 2 \frac{1}{n_k} \sum_j y_j^T C_k^{-1} \mu_k $


Now, under the approximation that returns $y_i$ are small (which has been used so far), $\sum_j y_jy_y^T \approx n_k C_k$ (remember that the summation in $j$ means condition on distribution $k$); also, we can neglect $\mu_k \mu_k^T (\approx 0)$.  Putting it all together

$\log p(D) \approx -\frac{n}{2} \left[ p\log(2\pi) + \sum_k \frac{n_k}{n}\log(\|C_k\|) + \sum_k \frac{n_k}{n} p -2 \sum_k \frac{n_k}{n} \frac{1}{n_k}\sum_j y_j^T C_k^{-1}\mu_k \right]$

or, more clean

$\log p(D) \approx -\frac{n}{2} p\log(2\pi) -\frac{1}{2} \sum_k n_k\log(\|C_k\|) - \frac{1}{2}\sum_k n_k p + \sum_k \sum_j y_j^T C_k^{-1}\mu_k $


where we can identify the last term as the returns of the strategy that invested according to $w_k^*$.

Even though we are measuring a quantity of practical interest such as the strategy performance, when we bet with $C^{-1}\mu$, it is a proxy to the probability of data given the model and makes it clear to compare models based on the strategy results.

