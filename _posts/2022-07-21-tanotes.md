
# Few notes on technical analysis

There are endless discussions about technical analysis: people like to look at indicators (well, we are _all_ trying to find indicators) to assess that prices are going to do this or that.

If we look at _all_ technical analysis, in the end, it is trying to measure _velocity_ (trend) and _acceleration_ (change in trend) in prices (charts). For example, when people say that the price is above some (most of the time, random) average it is trending up (and we expect this _velocity_ to continue) and also, when some reversion indicator (for example a RSI) is trigered people like to say that the movement is going to reverse - there is change in _velocity_ i.e _acceleration_.

Just to be clear, I am not a fan of this; everyone has an opinion on something that, by definition, should be deterministic and, everytime something happens in markets there is alwasy someone that, by pure change, had the indicator that _predicted_ that specific event. It is quite difficult to make a business out of this (if your business is making money not sell stories). 


Regardless of all of this, it may make sense to try to model these effects that people like to look and get a more _scientific_ view of the thing - in the end, if people look at trends and their changes and act accordingly, markets will react.


As said, it is always a good idea to think of these indicators as measures of trends and their change - everytime you see a price based indicator try to check which one it is _modelling_. More clearly, if we look at how they are constructed, all of them resemble some type of filter with an increasing complexity to try the impossible: reduce lag to zero..


## Analysis of the distribution of PnL with a moving average

A good place to start is to simulate a random walk, make a moving average, trade _on the trend_ - if the price is above[below] the average we buy[sell] - and visualize a histograms of the returns. This type of analysis is usefull in any indicator and can elucidate us to the exposition we will be subjected to.


```python
import numpy as np
import matplotlib.pyplot as plt
```


```python
# Note we are using a random walk, this is supposed to illustrate log-prices
# anyway this is irrelevant for the discussion
# we could have used a geometric brownian motion and study the distribution
# of percentage changes

def moving_average(x,w,pad=True):
    ma=np.convolve(x, np.ones(w,dtype=np.float),'valid')/float(w)
    if pad:
        ma=np.hstack((ma[0]*np.ones(w-1,dtype=np.float),ma))
    return ma

# simulate many points
n=50000
w=10

x=np.random.normal(0,1,n)
px=np.cumsum(x)
ma=moving_average(px,w,pad=True)

plt.title('Random Walk as proxy for prices')
plt.plot(px,label='Price')
plt.legend()
plt.grid()
plt.show()

# make trades
diff=px-ma
prev_diff=diff[:-1]
next_diff=diff[1:]
idx=np.where(prev_diff*next_diff<0)[0]+1
tps=px[idx]
r=tps[1:]-tps[:-1]
w=np.sign(diff[idx])[:-1]
r=r*w

plt.title('PnL pdf')
plt.hist(r,density=True,bins=30)
plt.grid(True)
plt.axvline(np.mean(r),color='k')
plt.show()

print('Average PnL: ', np.round(np.mean(r),1) )
```


![png](/images/tanotes/output_3_0.png)



![png](/images/tanotes/output_3_1.png)


    Average PnL:  0.0


First of all, we can notice that, as expected, using a moving average did not produce a positive expected value (it did not miracolously made money out of random price changes!). More interesting, the trade PnL profile is highly skewed to the right: we have many small losses and few large gains. I think this type of profile can make sense if you are making bets in a discretionary way (macro events or something like that): you have your own views - that should produce alpha (positive expected value!), you control your losses and let the profit of your idea run. 

This seems usefull but lots of people tend to just trace some lines in the chart and trade based on that. It will be quite difficult to make money that way.

Also, if you reverse the positions and trade on reversion, you will have a PnL distribution that is the inverse of this case: many small gains and few large losses.

Another thing, if our undelying process has some dependencies on the previous fluctuation (for example, an autoregressive process with positive correlation with the previous observation) then a moving average will make money but certainly is not the optimal choice of prediction method for the process in question.


This type of analysis is usefull if one thinks that indicator A or B is good (at your own peril!); we can gain intuition on the risk we are exposed to.


## Bayesian sequential estimation of a mean

Now we go to a more interesting interpretation of this type of indicators, and possibly, to a more fundamental interpretation of them (one that can allow us to estimate their parameters and/or determine when they can make sense).

Suppose that we observe data a point at a time, i.e, we do not have all data at the beginning but we receive one point after the other. How can we compute sequentially the mean of the data (update the mean as the data comes)?

To start, recall bayes rule:

$p(x\|y)=\frac{p(y,x)}{p(y)}=\frac{p(y\|x)p(x)}{p(y)}=\frac{p(y\|x)p(x)}{\int p(y\|x)p(x) \text{d}x}$

and the Gaussian distribution:

$p(x)=\frac{1}{\sqrt{2\pi \sigma^2}} \exp \left[ \frac{-(x-\mu)^2}{2\sigma^2} \right]$

Now, we can observe that, if we have a Gaussian prior, $p(x)=N(x;x_0,\sigma_0^2)$ and a Gaussian likelihood $p(y\|x)=N(y;x,\sigma_D^2)$, then the posterior, $p(x\|y)$, is Gaussian like $N(x;m,\sigma^2)$ with $\sigma^2=1/\sigma_0^2 + 1/\sigma_D^2$ and $m=x_0 \sigma^2 / \sigma_0^2 + y \sigma^2 / \sigma_D^2$.


So, for our case, if our current estimate of the mean is $\mu_t$ and variance is $\sigma_t^2$ (these are the parameters of the distribution of the points that we see; we are interested in the mean of the distribution!) then we can say that out prior distribution for the mean (before observing new point $x_t$) is Gaussian like 

$p(\mu_t)=N(\mu_t;\mu_t,\sigma_t^2 / t)$

where the term $\sigma_t^2 / t$ comes from the known formula for the distribution of the mean (which is what we want).

The likelihood of this new point is:


$p(x_t\|\mu_t)=N(x_t;\mu_t,\sigma_t^2)$


With the formulas above, this means that our update to the mean is

$\mu_{t+1}=\frac{t}{t+1}\mu_t + \frac{1}{t+1} x_t$

Let us build an example:



```python
mu=1
scale=0.5
n=500
mu_est=np.zeros(n,dtype=float)
mu_init=0
mu_est[0]=mu_init
for i in range(1,n):
    x=np.random.normal(mu,scale)
    mu_est[i]=i*mu_est[i-1]/(i+1)+x/(i+1)
plt.title('Sequential estimation of mean')
plt.plot(mu_est,color='k',label='Sequestial estimator')
plt.axhline(mu,color='r',label='True mean')
plt.legend()
plt.grid(True)
plt.show()
```


![png](/images/tanotes/output_6_0.png)


Of course this example is not that useful but it set us up for more complicated stuff.

Let us consider the case where the mean is non-stationary (it can drift); also let the drift be random:

$\mu_t=\mu_{t-1}+w_t$

where $w_t$ is Gaussian $p(w)=N(w;0,\sigma_w^2)$. The observations $x_t$ are generated from a Gaussian centered in $\mu_t$, i.e, $p(x_t)=N(x_t;\mu_t,\sigma_2)$.

This is a random walk with noise. Let us illustrade this by simulating the process.


```python
scale_w=0.1
scale_x=0.1
n=200

mu=np.cumsum(np.random.normal(0,scale_w,n))
x=np.random.normal(mu,scale_x)

plt.title('Random Walk with Noise')
plt.plot(mu,color='k',label='Non-stationary mean')
plt.plot(x,color='r',label='Observed Process')
plt.grid(True)
plt.legend()
plt.show()
```


![png](/images/tanotes/output_8_0.png)


Let us build an algorithm to estimate the non-stationary mean in a sequential manner (as we get observation of $x$).

To start, consider that we have estimates for the distribution of the location of the mean, i.e, $p(\mu_{t-1})=N(\mu_{t-1};\hat \mu_{t-1},\hat \sigma_{t-1}^2)$. Given that, our prior distribution for $\mu_t$ is $N(\mu_t;\hat \mu_{t-1}, r_t)$; $r_t$ is our prior variance which is $r_t=\hat \sigma_{t-1}^2 + \sigma_w^2$ because we need to add the variance of the drift and the estimated variace that we already had (notice that, $\hat \sigma$ is an estimator of the variance of our estimate of the mean; in the previous case we could make a direct correspondence with the variance of the data with $\sigma/t$ but here this is not valid anymore).

In the same fashion as in the stationary case, the likelihood of the observation is $p(x_t\|\mu_t)=N(x_t;\hat \mu_{t-1},\sigma_x^2)$.

Using the same formulas, our posterior (after observing $x_t$) is $p(\mu_t\|x_t)=N(\mu_t;\hat \mu_t, \hat \sigma_t^2)$ with


$\hat \mu_t=\hat \mu_{t-1} + \frac{r_t}{\sigma_x^2+r_t} (x_t-\hat \mu_{t-1})$

$\hat \sigma_t^2 = \frac{r_t \sigma_x^2}{r_t + \sigma_x^2}$


For ease of interpretation, let us write it as:

$\hat \mu_t=\hat \mu_{t-1} + K_t e_t$

$\hat \sigma_t^2 = r_t(1-K_t)$

$K_t=\frac{r_t}{r_t + \sigma_x^2}$

$e_t=x_t-\hat \mu_{t-1}$

This is a simple case of a Kalman filter ($K_t$ is the Kalman gain).



Interesting for our case here, we can observe that $\hat \mu_t=K_t x_t + \hat \mu_{t-1}(1-K_t)$, $K_t \in (0,1)$ and after a while $K_t$ should stabilize to a constant given that we reach some stability in the estimation of $\hat \sigma_t^2$.

This makes this estimator _exactly_ like a exponential moving average! Without further information, a blind application of a moving average makes sense to estimate a random walk with noise and so, for trading applications, what makes sense is to trade the reversion to the mean (which is the tradeable signal that is present in the process). We should be more contained when talking about trading with trends with a moving average as the stochastic process where this indicator makes sense does not trade that way.

Anyway, let us implement this.



```python
# we are assuming we know the parameters of the process
# in a real setup we may have to learn them by ME
# this will stay in another post

mu_est=np.zeros(x.size)
sigma_est=np.zeros(x.size)

for i in range(1,x.size):
    e=x[i]-mu_est[i-1]
    r=sigma_est[i-1]*sigma_est[i-1] + scale_w*scale_w
    K=r/(r+scale_x*scale_x)
    mu_est[i]=mu_est[i-1]+K*e
    sigma_est[i]=r*(1-K)
    
plt.title('Random Walk with Noise')
plt.plot(mu,color='k',label='Non-stationary mean')
plt.plot(x,color='r',label='Observed Process')
plt.plot(mu_est,color='b',label='Estimated Non-stationary mean')
plt.grid(True)
plt.legend()
plt.show()



```


![png](/images/tanotes/output_10_0.png)


A way to trade this is to assume that the process will revert to the estimated mean. 


### Final idea

The point of this post is to make the observation that, although there are many popular indicators, most of them try to represent the same information and, it is more useful to build a stochastic process (with the features that we think relevant; here we used a random walk with noise to illustrate that its solution is a moving average!), estimate its parameters (not covered here) and trade them: in this case, clearly, we have a distribution for the next value of $x_t$ that we can use to make bets.


